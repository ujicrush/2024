{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling up\n",
    "\n",
    "Originally released as part of a homework in ADA2019.\n",
    "\n",
    "## Description\n",
    "\n",
    "[Reddit](https://www.reddit.com/) aka *'the front page of the internet'* is a network of over a million *communities* aka *'subreddits'*, each of which covers a different topic based on people's interests. In other words, it is a *massive* collection of forums (corresponding to the aforementioned communities), where people can share content specific to a given topic or comment on other people’s posts.   \n",
    "\n",
    "You are reddit's community manager and want to *appoint new moderators*. Because moderating a specific subreddit isn't a full-time job, you want the chosen moderators to moderate multiple subreddits at the same time. To make this choice effective, the moderators shouldn't have to spend too much time getting to know the community and the prevalent communication style, so it makes sense to let moderators moderate subreddits that are similar in communication style and language. At the same time, it also makes sense to let them moderate subreddits that are similar with respect to the participating users, because this allows moderators to track the behavior of individual users over multiple subreddits. For example, some users might only post offensive content once a month on a given subreddit, and therefore fly under the radar with someone moderating only that subreddit. However, considering all the subreddits these users post to, they might post something offensive every day but on different subreddits. Thus, a moderator in charge of all these subreddits would be able to ban such users much more effectively. In the light of the above description, your task is to find out ways to choose moderators considering both the textual content and the users of a subreddit.\n",
    "\n",
    "### Dataset:\n",
    "The dataset provided to you includes all the posts of the 15 largest subreddits written as of May 2015.\n",
    "\n",
    "Reddit posts (provided to you via a [google drive folder](https://drive.google.com/a/epfl.ch/file/d/19SVHKbUTUPtC9HMmADJcAAIY1Xjq6WFv/view?usp=sharing))\n",
    "```\n",
    "reddit_posts\n",
    " |-- id: id of the post \n",
    " |-- author: user name of the author \n",
    " |-- body: text of the message\n",
    " |-- subreddit: name of the subreddit\n",
    "```\n",
    "\n",
    "Reddit scores (provided to you via a [google drive folder](https://drive.google.com/a/epfl.ch/file/d/1vr4PolJzTXr6ODSe3ucib5EAyp3rjxec/view?usp=sharing))\n",
    "```\n",
    "reddit_scores\n",
    " |-- id: id of the post \n",
    " |-- score: score computed as sum of UP/DOWN votes\n",
    "```\n",
    "\n",
    "*Note: Jaccard similarity between subreddits represented using either the set of top-1000 words or the set of users can be computed locally (on the driver), however, all the other tasks have to be implemented in Spark.*\n",
    "\n",
    "## B1. Getting a sense of the data\n",
    "\n",
    "Start a PySpark instance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.100.4.153:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c22fb2e1f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAll([\n",
    "                                   ('spark.executor.memory', '12g'),  # find\n",
    "                                   ('spark.driver.memory','4g'), # your\n",
    "                                   ('spark.driver.maxResultSize', '2G') # setup\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(\"spark.sql.broadcastTimeout\", \"1200\").getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# FIX for Spark 2.x\n",
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON']='D:\\\\Users\\\\uji_crush\\\\anaconda3\\\\envs\\\\ada\\\\python.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and load the data in a Spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reddit = spark.read.json(\"messages.json.gz\")\n",
    "score = spark.read.json(\"score.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run hw2_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[id: string, score: bigint]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1.1. Identify the most active subreddit\n",
    "\n",
    "Print the list of subreddits along with the following information:\n",
    "1. The total number of posts\n",
    "2. The number of users with at least 1 message\n",
    "3. The mean message length\n",
    "\n",
    "*Note: Keep everything in one single dataframe and print the list sorted by number of posts in descending order.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[subreddit: string, total_posts: bigint, users_count: bigint, posts_length: double, posts_length_stddev: double]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_info = reddit.groupBy(\"subreddit\").agg(count(\"*\").alias(\"total_posts\"), \n",
    "                                                 countDistinct(\"author\").alias(\"users_count\"), \n",
    "                                                 avg(length(\"body\")).alias(\"posts_length\"), \n",
    "                                                 stddev(length(\"body\")).alias(\"posts_length_stddev\")\n",
    "                                                ).cache()\n",
    "subreddit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_total_posts = subreddit_info.sort(col(\"total_posts\").desc()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>users_count</th>\n",
       "      <th>posts_length</th>\n",
       "      <th>posts_length_stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1151287</td>\n",
       "      <td>119321</td>\n",
       "      <td>152.722808</td>\n",
       "      <td>256.314799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nba</td>\n",
       "      <td>704862</td>\n",
       "      <td>45034</td>\n",
       "      <td>106.486568</td>\n",
       "      <td>166.523158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>691139</td>\n",
       "      <td>224077</td>\n",
       "      <td>106.822839</td>\n",
       "      <td>184.536908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pics</td>\n",
       "      <td>564502</td>\n",
       "      <td>205305</td>\n",
       "      <td>114.971005</td>\n",
       "      <td>198.637008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl</td>\n",
       "      <td>534345</td>\n",
       "      <td>41593</td>\n",
       "      <td>148.969892</td>\n",
       "      <td>237.641786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>videos</td>\n",
       "      <td>511492</td>\n",
       "      <td>157628</td>\n",
       "      <td>170.227026</td>\n",
       "      <td>290.461162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>477658</td>\n",
       "      <td>98736</td>\n",
       "      <td>230.949160</td>\n",
       "      <td>334.516180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DestinyTheGame</td>\n",
       "      <td>471160</td>\n",
       "      <td>37008</td>\n",
       "      <td>165.417869</td>\n",
       "      <td>225.444718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>soccer</td>\n",
       "      <td>455215</td>\n",
       "      <td>41648</td>\n",
       "      <td>134.422247</td>\n",
       "      <td>203.639870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>445154</td>\n",
       "      <td>41466</td>\n",
       "      <td>141.489067</td>\n",
       "      <td>258.451712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>439417</td>\n",
       "      <td>99261</td>\n",
       "      <td>224.937547</td>\n",
       "      <td>355.402419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>411902</td>\n",
       "      <td>115815</td>\n",
       "      <td>159.251380</td>\n",
       "      <td>238.983449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hockey</td>\n",
       "      <td>389329</td>\n",
       "      <td>25568</td>\n",
       "      <td>95.372872</td>\n",
       "      <td>163.424626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>382017</td>\n",
       "      <td>46686</td>\n",
       "      <td>147.288398</td>\n",
       "      <td>229.592384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>movies</td>\n",
       "      <td>354601</td>\n",
       "      <td>92484</td>\n",
       "      <td>164.832093</td>\n",
       "      <td>255.503286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  total_posts  users_count  posts_length  \\\n",
       "0   leagueoflegends      1151287       119321    152.722808   \n",
       "1               nba       704862        45034    106.486568   \n",
       "2             funny       691139       224077    106.822839   \n",
       "3              pics       564502       205305    114.971005   \n",
       "4               nfl       534345        41593    148.969892   \n",
       "5            videos       511492       157628    170.227026   \n",
       "6              news       477658        98736    230.949160   \n",
       "7    DestinyTheGame       471160        37008    165.417869   \n",
       "8            soccer       455215        41648    134.422247   \n",
       "9             DotA2       445154        41466    141.489067   \n",
       "10        worldnews       439417        99261    224.937547   \n",
       "11    AdviceAnimals       411902       115815    159.251380   \n",
       "12           hockey       389329        25568     95.372872   \n",
       "13  GlobalOffensive       382017        46686    147.288398   \n",
       "14           movies       354601        92484    164.832093   \n",
       "\n",
       "    posts_length_stddev  \n",
       "0            256.314799  \n",
       "1            166.523158  \n",
       "2            184.536908  \n",
       "3            198.637008  \n",
       "4            237.641786  \n",
       "5            290.461162  \n",
       "6            334.516180  \n",
       "7            225.444718  \n",
       "8            203.639870  \n",
       "9            258.451712  \n",
       "10           355.402419  \n",
       "11           238.983449  \n",
       "12           163.424626  \n",
       "13           229.592384  \n",
       "14           255.503286  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_total_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1.2. Identify the largest subreddit\n",
    "\n",
    "Print *two* different lists of subreddits: ordered by (1) the number of posts, and (2) the number of users. For each subreddit, print the name and the corresponding counts.\n",
    "\n",
    "Additionally, (3) plot the mean of message length for each subreddit in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>total_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1151287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nba</td>\n",
       "      <td>704862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>691139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pics</td>\n",
       "      <td>564502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl</td>\n",
       "      <td>534345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>videos</td>\n",
       "      <td>511492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>477658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DestinyTheGame</td>\n",
       "      <td>471160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>soccer</td>\n",
       "      <td>455215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>445154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>439417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>411902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hockey</td>\n",
       "      <td>389329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>382017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>movies</td>\n",
       "      <td>354601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>users_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>224077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pics</td>\n",
       "      <td>205305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>videos</td>\n",
       "      <td>157628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>119321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>115815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>99261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>98736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movies</td>\n",
       "      <td>92484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>46686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nba</td>\n",
       "      <td>45034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>soccer</td>\n",
       "      <td>41648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nfl</td>\n",
       "      <td>41593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>41466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DestinyTheGame</td>\n",
       "      <td>37008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hockey</td>\n",
       "      <td>25568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "by_posts = subreddit_info.select(\"subreddit\",\"total_posts\").sort(col(\"total_posts\").desc()).toPandas()\n",
    "by_users = subreddit_info.select(\"subreddit\",\"users_count\").sort(col(\"users_count\").desc()).toPandas()\n",
    "\n",
    "display_side_by_side(by_posts, by_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>users_count</th>\n",
       "      <th>posts_length</th>\n",
       "      <th>posts_length_stddev</th>\n",
       "      <th>ci99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>477658</td>\n",
       "      <td>98736</td>\n",
       "      <td>230.949160</td>\n",
       "      <td>334.516180</td>\n",
       "      <td>1.246822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>439417</td>\n",
       "      <td>99261</td>\n",
       "      <td>224.937547</td>\n",
       "      <td>355.402419</td>\n",
       "      <td>1.381109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>videos</td>\n",
       "      <td>511492</td>\n",
       "      <td>157628</td>\n",
       "      <td>170.227026</td>\n",
       "      <td>290.461162</td>\n",
       "      <td>1.046199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DestinyTheGame</td>\n",
       "      <td>471160</td>\n",
       "      <td>37008</td>\n",
       "      <td>165.417869</td>\n",
       "      <td>225.444718</td>\n",
       "      <td>0.846061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movies</td>\n",
       "      <td>354601</td>\n",
       "      <td>92484</td>\n",
       "      <td>164.832093</td>\n",
       "      <td>255.503286</td>\n",
       "      <td>1.105280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>411902</td>\n",
       "      <td>115815</td>\n",
       "      <td>159.251380</td>\n",
       "      <td>238.983449</td>\n",
       "      <td>0.959217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1151287</td>\n",
       "      <td>119321</td>\n",
       "      <td>152.722808</td>\n",
       "      <td>256.314799</td>\n",
       "      <td>0.615358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nfl</td>\n",
       "      <td>534345</td>\n",
       "      <td>41593</td>\n",
       "      <td>148.969892</td>\n",
       "      <td>237.641786</td>\n",
       "      <td>0.837448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>382017</td>\n",
       "      <td>46686</td>\n",
       "      <td>147.288398</td>\n",
       "      <td>229.592384</td>\n",
       "      <td>0.956890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>445154</td>\n",
       "      <td>41466</td>\n",
       "      <td>141.489067</td>\n",
       "      <td>258.451712</td>\n",
       "      <td>0.997861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>soccer</td>\n",
       "      <td>455215</td>\n",
       "      <td>41648</td>\n",
       "      <td>134.422247</td>\n",
       "      <td>203.639870</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pics</td>\n",
       "      <td>564502</td>\n",
       "      <td>205305</td>\n",
       "      <td>114.971005</td>\n",
       "      <td>198.637008</td>\n",
       "      <td>0.681041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>funny</td>\n",
       "      <td>691139</td>\n",
       "      <td>224077</td>\n",
       "      <td>106.822839</td>\n",
       "      <td>184.536908</td>\n",
       "      <td>0.571803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nba</td>\n",
       "      <td>704862</td>\n",
       "      <td>45034</td>\n",
       "      <td>106.486568</td>\n",
       "      <td>166.523158</td>\n",
       "      <td>0.510938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hockey</td>\n",
       "      <td>389329</td>\n",
       "      <td>25568</td>\n",
       "      <td>95.372872</td>\n",
       "      <td>163.424626</td>\n",
       "      <td>0.674691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  total_posts  users_count  posts_length  \\\n",
       "0              news       477658        98736    230.949160   \n",
       "1         worldnews       439417        99261    224.937547   \n",
       "2            videos       511492       157628    170.227026   \n",
       "3    DestinyTheGame       471160        37008    165.417869   \n",
       "4            movies       354601        92484    164.832093   \n",
       "5     AdviceAnimals       411902       115815    159.251380   \n",
       "6   leagueoflegends      1151287       119321    152.722808   \n",
       "7               nfl       534345        41593    148.969892   \n",
       "8   GlobalOffensive       382017        46686    147.288398   \n",
       "9             DotA2       445154        41466    141.489067   \n",
       "10           soccer       455215        41648    134.422247   \n",
       "11             pics       564502       205305    114.971005   \n",
       "12            funny       691139       224077    106.822839   \n",
       "13              nba       704862        45034    106.486568   \n",
       "14           hockey       389329        25568     95.372872   \n",
       "\n",
       "    posts_length_stddev      ci99  \n",
       "0            334.516180  1.246822  \n",
       "1            355.402419  1.381109  \n",
       "2            290.461162  1.046199  \n",
       "3            225.444718  0.846061  \n",
       "4            255.503286  1.105280  \n",
       "5            238.983449  0.959217  \n",
       "6            256.314799  0.615358  \n",
       "7            237.641786  0.837448  \n",
       "8            229.592384  0.956890  \n",
       "9            258.451712  0.997861  \n",
       "10           203.639870  0.777500  \n",
       "11           198.637008  0.681041  \n",
       "12           184.536908  0.571803  \n",
       "13           166.523158  0.510938  \n",
       "14           163.424626  0.674691  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# .reset_index(drop=True): 重置索引，并删除原来的索引，确保索引从0开始\n",
    "subreddit_by_pl = subreddit_info.toPandas().sort_values(\"posts_length\",ascending=False).reset_index(drop=True)\n",
    "sqrt_N = subreddit_by_pl['total_posts'].apply(lambda r: math.sqrt(r))\n",
    "subreddit_by_pl['ci99'] = 2.576 * (subreddit_by_pl['posts_length_stddev'] / sqrt_N)\n",
    "\n",
    "subreddit_by_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(y=subreddit_by_pl['subreddit'],width=subreddit_by_pl['posts_length'], xerr=subreddit_by_pl['ci99'])\n",
    "plt.xlabel('Post length average (CI 99%)')\n",
    "plt.ylabel('Subreddit')\n",
    "plt.title('Average posts length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1.3. Identify the subreddit with the highest average score\n",
    "\n",
    "Print the list of subreddits sorted by their average content scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|      subreddit|             score|\n",
      "+---------------+------------------+\n",
      "|         videos|12.649445152612358|\n",
      "|           pics|12.216559020162904|\n",
      "|          funny|12.041505399058655|\n",
      "|  AdviceAnimals|11.251695791717447|\n",
      "|         soccer|10.634627593554693|\n",
      "|         movies|  9.82014997137628|\n",
      "|            nfl| 9.048348913155358|\n",
      "|            nba| 9.032795071943161|\n",
      "|           news| 8.673421150697779|\n",
      "|      worldnews|  7.86683719564787|\n",
      "|         hockey| 6.520120515039979|\n",
      "|leagueoflegends| 5.983557531701479|\n",
      "|          DotA2| 4.880537971129092|\n",
      "|GlobalOffensive| 4.351442475073099|\n",
      "| DestinyTheGame|3.0288819084811953|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.join(score,\"id\").groupBy(\"subreddit\").agg(avg(\"score\").alias(\"score\")).sort(col(\"score\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. Moderator assignment based on Subreddit Textual Content\n",
    "\n",
    "Different subreddits follow different communication styles inherent in the topic and the community. Having said that, the goal is to discover similar subreddits by only looking at the *words* present in the posted messages. Once such a list of similar subreddits is identified, an appropriately chosen moderator can then be assigned to all these subreddits.\n",
    "\n",
    "Specifically, the task boils down to computing a similarity score between two subreddits based on the *words* present in their textual content. Your first idea is to use the *Jaccard similarity*, which is defined as the size of the intersection of two sets divided by the size of their union.\n",
    "\n",
    "$Jaccard(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2.1.\n",
    "The first step requires constructing a set representation of each subreddit. The goal is to represent each subreddit as a *set of words* existing in the messages posted on that subreddit. Compute the 50,000 most frequent words across all the provided subreddits. Construct a representation for each subreddit by retaining only the words found in the previously identified set of 50,000 frequent words.\n",
    "\n",
    "Some rules:\n",
    " * Words are defined as tokens matching the regular expression `\\W`\n",
    " * Remove all the stop-words (English language)\n",
    "\n",
    "*Note: You might find the [RegexTokenizer](https://spark.apache.org/docs/2.2.0/ml-features.html#tokenizer) and the [StopWordsRemover](https://spark.apache.org/docs/2.2.0/ml-features.html#stopwordsremover) utilities available in the package pyspark.ml useful for this task as they help you in transforming the features and removing stopwords.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------+---------------+--------------------+\n",
      "|           author|                body|     id|      subreddit|               words|\n",
      "+-----------------+--------------------+-------+---------------+--------------------+\n",
      "|        WyaOfWade|gg this one's ove...|cqug90h|            nba|[gg, one, watch, ...|\n",
      "|        BEE_REAL_|Nihilum and LG ar...|cqug90p|GlobalOffensive|[nihilum, lg, sig...|\n",
      "|        SlowRolla|Me too. Same hamm...|cqug916|           pics|   [hammock, fabric]|\n",
      "|   SenpaiOniichan|well i think new ...|cqug919|leagueoflegends|[well, think, new...|\n",
      "|backwoodsofcanada|That's something ...|cqug91n|  AdviceAnimals|[something, hear,...|\n",
      "+-----------------+--------------------+-------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "# tokenize the text\n",
    "# RegexTokenizer是 Spark ML 提供的文本分词工具，它通过正则表达式将输入文本拆分为单词列表\n",
    "# inputCol=\"body\"：指定输入列为 body\n",
    "# outputCol=\"all_words\"：将分词结果存入新的列 all_words 中\n",
    "# pattern=\"\\\\W\"：正则表达式模式，\\\\W 表示 \"非单词字符\"（例如空格、标点符号等），用作分词的边界\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"all_words\", pattern=\"\\\\W\")\n",
    "reddit_with_words = regexTokenizer.transform(reddit)\n",
    "\n",
    "# remove stop words\n",
    "# StopWordsRemover 是 Spark ML 提供的停用词过滤工具，旨在从单词列表中移除常见但信息量较低的词汇\n",
    "remover = StopWordsRemover(inputCol=\"all_words\", outputCol=\"words\")\n",
    "reddit_with_tokens = remover.transform(reddit_with_words).drop(\"all_words\")\n",
    "\n",
    "reddit_with_tokens.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|  word|  total|\n",
      "+------+-------+\n",
      "|  like|1018978|\n",
      "|people| 745031|\n",
      "|   get| 691349|\n",
      "|   one| 682820|\n",
      "| think| 575352|\n",
      "|     m| 569057|\n",
      "|    re| 517827|\n",
      "|   com| 497303|\n",
      "|  time| 456060|\n",
      "|  good| 454768|\n",
      "|  game| 452376|\n",
      "|really| 451527|\n",
      "|  even| 432973|\n",
      "|  know| 413379|\n",
      "|    gt| 404776|\n",
      "|  http| 395552|\n",
      "|  well| 352021|\n",
      "|   see| 351081|\n",
      "|  much| 348304|\n",
      "|  also| 333478|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the 50,000 most frequent words across all the subreddits.\n",
    "\n",
    "# get all words in a single dataframe\n",
    "# explode(\"words\"): 将数组列拆分成多行。每个数组中的元素（即单词）都会成为新表中的一行\n",
    "all_words = reddit_with_tokens.select(explode(\"words\").alias(\"word\"))\n",
    "\n",
    "# group by, sort and limit to 50k \n",
    "# limit(50000)：取出前 50,000 个单词\n",
    "top50k = all_words.groupBy(\"word\").agg(count(\"*\").alias(\"total\")).sort(col(\"total\").desc()).limit(100)\n",
    "\n",
    "top50k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[subreddit: string, word: string]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the words in a subreddit\n",
    "tokens = reddit_with_tokens.select(\"subreddit\", explode(\"words\").alias(\"word\")).distinct()  # .distinct(): 确保每个subreddit中每个单词只出现一次\n",
    "# Join with the whitelist of the top 50k\n",
    "# tokens.alias(\"t\")：给 tokens 起一个别名 \"t\"，以便在连接操作中引用\n",
    "# join(top50k, tokens.word == top50k.word): 将 tokens 与 top50k 按 word 列进行内连接（inner join）\n",
    "# 只保留 tokens 中那些 word 存在于 top50k 的行\n",
    "# select(\"t.*\"): 选择过滤后的 tokens 中的所有列（subreddit 和 word）, 忽略 top50k 中的额外列（如 total ）\n",
    "\n",
    "filtered_tokens = tokens.alias(\"t\").join(top50k, tokens.word==top50k.word).select(\"t.*\")\n",
    "\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 127.0 failed 1 times, most recent failure: Lost task 5.0 in stage 127.0 (TID 7225) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# .reduceByKey(lambda a, b: a + b): 按照 subreddit 进行分组，并将每个 subreddit 的单词列表合并成一个完整列表\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# .collect(): 将计算结果从分布式 RDD 中收集到驱动程序（driver）节点，并返回一个 Python 列表\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m subreddit_50k \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubreddit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduceByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:949\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;124;03mReturn a list that contains all of the elements in this RDD.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03mto be small, as all the data is loaded into the driver's memory.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[1;32m--> 949\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 127.0 failed 1 times, most recent failure: Lost task 5.0 in stage 127.0 (TID 7225) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n"
     ]
    }
   ],
   "source": [
    "# .reduceByKey(lambda a, b: a + b): 按照 subreddit 进行分组，并将每个 subreddit 的单词列表合并成一个完整列表\n",
    "# .collect(): 将计算结果从分布式 RDD 中收集到驱动程序（driver）节点，并返回一个 Python 列表\n",
    "subreddit_50k = filtered_tokens.rdd.map(lambda r: (r.subreddit, [r.word])).reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sr in subreddit_50k:\n",
    "    print(\"Subreddit: {} - Words: {}\".format(sr[0], len(sr[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2.2.\n",
    "* Compute the Jaccard similarity between all the subreddits using the set representation obtained in step **B2.1.**, and plot in a heatmap the similarity values of all the pairs of subreddits.\n",
    "* Analyze this plot and discuss your observations. Do you observe that subreddits corresponding to similar topics possess higher Jaccard similarity?\n",
    "* Provide detailed interpretations of the obtained results. Specifically,\n",
    "    - Explain the limitations of your conclusions, and discuss the potential reasons.\n",
    "    - Explain the potential problems with the Jaccard similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: similarity is computed 2 times! It can be optimized\n",
    "similarity = []     # 一个空列表，用于存储每对子版块之间的相似度计算结果\n",
    "for sr1 in subreddit_50k:\n",
    "    for sr2 in subreddit_50k:\n",
    "        similarity.append((sr1[0], sr2[0], jaccard_similarity(sr1[1], sr2[1])))\n",
    "\n",
    "# .pivot(index=0, columns=1, values=2)：将 DataFrame 转换为一个矩阵形式\n",
    "# index=0：第一列（子版块 1 名字）作为行索引\n",
    "# columns=1：第二列（子版块 2 名字）作为列索引\n",
    "# values=2：第三列（Jaccard 相似度值）作为矩阵的值\n",
    "similarity_matrix_50k_words = pd.DataFrame(similarity).pivot(index=0, columns=1, values=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码的作用是计算两个子版块（subreddit）之间基于它们使用的单词的 **Jaccard 相似度**，并将所有子版块的相似度结果存储在一个 **相似度矩阵（similarity matrix）** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(similarity_matrix_50k_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2.3.\n",
    "\n",
    "* Alternatively, compute the 1000 most frequent words for each subreddit, construct its representation as the set of top-1000 words, and print a heatmap with the Jaccard similarity like in step **B2.2.**.\n",
    "* Explain your observations in detail: how and why is this new result different from the one obtained in **B2.2.**?\n",
    "\n",
    "*Note: Use the same rules specified in B2.1: words tokenized with the regex \\W and stop-words removed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 129.0 failed 1 times, most recent failure: Lost task 0.0 in stage 129.0 (TID 7237) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m words_count_by_subreddit_rdd \u001b[38;5;241m=\u001b[39m reddit_with_tokens\u001b[38;5;241m.\u001b[39mrdd\\\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mflatMap(\u001b[38;5;28;01mlambda\u001b[39;00m r: [((r\u001b[38;5;241m.\u001b[39msubreddit, w), \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mwords])\\\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mreduceByKey(\u001b[38;5;28;01mlambda\u001b[39;00m a,b: a\u001b[38;5;241m+\u001b[39mb)\u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# conversion in a dataframe\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# words_count_by_subreddit_rdd 中的每个元素r转换为行对象Row\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 将子版块名r[0][0]、单词r[0][1]以及单词计数r[1]映射为 DataFrame 的列\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m words_count_by_subreddit \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwords_count_by_subreddit_rdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRow\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubreddit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Window on the words grouped by subreddit\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 按子版块分组，计算单词排名\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Window.partitionBy：按子版块subreddit分组，给每个子版块创建一个独立的窗口\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# orderBy：窗口内的单词按出现频率count从高到低排序\u001b[39;00m\n\u001b[0;32m     21\u001b[0m window \u001b[38;5;241m=\u001b[39m Window\u001b[38;5;241m.\u001b[39mpartitionBy(words_count_by_subreddit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39morderBy(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:675\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m    674\u001b[0m         data, schema, samplingRatio, verifySchema)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:698\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    695\u001b[0m     prepare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m obj: obj\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, RDD):\n\u001b[1;32m--> 698\u001b[0m     rdd, schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromRDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     rdd, schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:486\u001b[0m, in \u001b[0;36mSparkSession._createFromRDD\u001b[1;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03mCreate an RDD for DataFrame from an existing RDD, returns the RDD and schema.\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 486\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[0;32m    488\u001b[0m     rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(converter)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:460\u001b[0m, in \u001b[0;36mSparkSession._inferSchema\u001b[1;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inferSchema\u001b[39m(\u001b[38;5;28mself\u001b[39m, rdd, samplingRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    Infer schema from an RDD of Row, dict, or tuple.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03m    :class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first row in RDD is empty, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan not infer schema\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:1586\u001b[0m, in \u001b[0;36mRDD.first\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;124;03m    Return the first element in this RDD.\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;124;03m    ValueError: RDD is empty\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[0;32m   1588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:1566\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1563\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1565\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 1566\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   1569\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\context.py:1233\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;66;03m# Implementation note: This is implemented as a mapPartitions followed\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;66;03m# by runJob() in order to avoid having to pass a Python lambda into\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;66;03m# SparkContext#runJob.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m-> 1233\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 129.0 failed 1 times, most recent failure: Lost task 0.0 in stage 129.0 (TID 7237) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n"
     ]
    }
   ],
   "source": [
    "# Word count at subreddit level\n",
    "# 计算每个单词在子版块中的词频\n",
    "# flatMap：每行r是一个帖子。每个帖子中，我们从r.words中提取每个单词w。将每个单词与子版块r.subreddit组合成一个键值对：((subreddit, word), 1)\n",
    "# reduceByKey：对每个键（子版块和单词的组合）进行聚合，计算每个单词在每个子版块中的总出现次数\n",
    "# words_count_by_subreddit_rdd 包含每个子版块中每个单词的词频\n",
    "words_count_by_subreddit_rdd = reddit_with_tokens.rdd\\\n",
    "    .flatMap(lambda r: [((r.subreddit, w), 1) for w in r.words])\\\n",
    "    .reduceByKey(lambda a,b: a+b).cache()\n",
    "\n",
    "# conversion in a dataframe\n",
    "# words_count_by_subreddit_rdd 中的每个元素r转换为行对象Row\n",
    "# 将子版块名r[0][0]、单词r[0][1]以及单词计数r[1]映射为 DataFrame 的列\n",
    "words_count_by_subreddit = spark.createDataFrame(\n",
    "            words_count_by_subreddit_rdd.map(lambda r: Row(subreddit=r[0][0], word=r[0][1], count=r[1]))\n",
    ")\n",
    "\n",
    "# Window on the words grouped by subreddit\n",
    "# 按子版块分组，计算单词排名\n",
    "# Window.partitionBy：按子版块subreddit分组，给每个子版块创建一个独立的窗口\n",
    "# orderBy：窗口内的单词按出现频率count从高到低排序\n",
    "window = Window.partitionBy(words_count_by_subreddit['subreddit']).orderBy(col('count').desc())\n",
    "\n",
    "# Add position with rank() function (rowNumber is accepted, and it would be more correct)\n",
    "# 在每个窗口内（即每个子版块），按单词频率排序，为每个单词分配排名（rank）\n",
    "# rdd.map：将筛选后的 DataFrame 转换为 RDD 格式，将每一行映射为(subreddit, [word])的格式\n",
    "top1000_rdd = words_count_by_subreddit.select('*', rank().over(window).alias('rank'))\\\n",
    "  .filter(col('rank') <= 1000).rdd.map(lambda r: (r.subreddit, [r.word])).reduceByKey(lambda a,b: a+b)\n",
    "\n",
    "top1000 = top1000_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3. Moderator assignment based on Subreddit Users\n",
    "\n",
    "Subreddits can be seen as communities of people interacting about a common topic. As an alternative to the *textual content* based similarity in **B2**, your task here is to validate if similarity between two subreddits can be measured based on their participating users.\n",
    "\n",
    "Of course users are not monothematic, and they interact with multiple subreddits. In this task, we are specifically interested in observing the amount of overlap across different subreddits based on their participating users. Similar to **B2**, the overlap is measured using the *Jaccard similarity*.\n",
    "\n",
    "\n",
    "### B3.1.\n",
    "Construct a set representation of each subreddit as the users that posted at least one time in that subreddit.\n",
    "\n",
    "Some users are very talkative and active across different topics. Print the username of the person that posted in the maximum number of subreddits. *Note that users who posted at least once in a subreddit are considered as participant of that subreddit.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 132.0 failed 1 times, most recent failure: Lost task 12.0 in stage 132.0 (TID 7251) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m user_in_communities_rdd \u001b[38;5;241m=\u001b[39m reddit\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m r: (r\u001b[38;5;241m.\u001b[39mauthor, \u001b[38;5;241m1\u001b[39m))\\\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mreduceByKey(\u001b[38;5;28;01mlambda\u001b[39;00m a,b: a\u001b[38;5;241m+\u001b[39mb)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m r: Row(author\u001b[38;5;241m=\u001b[39mr[\u001b[38;5;241m0\u001b[39m], communities\u001b[38;5;241m=\u001b[39mr[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a dataframe and sort\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# sort(col(\"communities\").desc()): 按 communities（用户参与的子版块数量）降序排序\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m user_in_communities \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_in_communities_rdd\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\n\u001b[0;32m     11\u001b[0m user_in_communities\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:675\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m    674\u001b[0m         data, schema, samplingRatio, verifySchema)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:698\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    695\u001b[0m     prepare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m obj: obj\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, RDD):\n\u001b[1;32m--> 698\u001b[0m     rdd, schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromRDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     rdd, schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:486\u001b[0m, in \u001b[0;36mSparkSession._createFromRDD\u001b[1;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03mCreate an RDD for DataFrame from an existing RDD, returns the RDD and schema.\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 486\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[0;32m    488\u001b[0m     rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(converter)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\session.py:460\u001b[0m, in \u001b[0;36mSparkSession._inferSchema\u001b[1;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inferSchema\u001b[39m(\u001b[38;5;28mself\u001b[39m, rdd, samplingRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    Infer schema from an RDD of Row, dict, or tuple.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03m    :class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first row in RDD is empty, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan not infer schema\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:1586\u001b[0m, in \u001b[0;36mRDD.first\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;124;03m    Return the first element in this RDD.\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;124;03m    ValueError: RDD is empty\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[0;32m   1588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:1566\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1563\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1565\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 1566\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   1569\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\context.py:1233\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;66;03m# Implementation note: This is implemented as a mapPartitions followed\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;66;03m# by runJob() in order to avoid having to pass a Python lambda into\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;66;03m# SparkContext#runJob.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m-> 1233\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 132.0 failed 1 times, most recent failure: Lost task 12.0 in stage 132.0 (TID 7251) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n"
     ]
    }
   ],
   "source": [
    "# .distinct(): 确保数据中每个(subreddit, author)对是唯一的, 避免重复计数同一个用户多次参与同一子版块\n",
    "# rdd.map(lambda r: (r.author, 1)): 将 DataFrame 转换为 RDD，将每一行映射为(author, 1)格式，author表示用户，1表示该用户参与了一个子版块\n",
    "# map(lambda r: Row(author=r[0], communities=r[1])): 将每个 (author, communities) 对转换为 Row 对象\n",
    "user_in_communities_rdd = reddit.select(\"subreddit\", \"author\").distinct().rdd.map(lambda r: (r.author, 1))\\\n",
    "    .reduceByKey(lambda a,b: a+b).map(lambda r: Row(author=r[0], communities=r[1]))\n",
    "\n",
    "# Create a dataframe and sort\n",
    "# sort(col(\"communities\").desc()): 按 communities（用户参与的子版块数量）降序排序\n",
    "user_in_communities = spark.createDataFrame(user_in_communities_rdd).sort(col(\"communities\").desc())\n",
    "\n",
    "user_in_communities.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3.2.\n",
    "\n",
    "* Compute the Jaccard similarity between all the subreddits using the set representation obtained in step **B3.1.**, and visualise it similar to **B2**.\n",
    "* Analyze this plot, identify highly similar pairs of subreddits, and clearly describe your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 135.0 failed 1 times, most recent failure: Lost task 0.0 in stage 135.0 (TID 7257) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mreddit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubreddit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistinct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubreddit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduceByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m similarity_users \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sr1 \u001b[38;5;129;01min\u001b[39;00m users:\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\rdd.py:949\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;124;03mReturn a list that contains all of the elements in this RDD.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03mto be small, as all the data is loaded into the driver's memory.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[1;32m--> 949\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\pyspark\\sql\\utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32md:\\Users\\uji_crush\\anaconda3\\envs\\pyspark\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 135.0 failed 1 times, most recent failure: Lost task 0.0 in stage 135.0 (TID 7257) (10.100.4.153 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 19 more\r\n"
     ]
    }
   ],
   "source": [
    "users = reddit.select(\"subreddit\", \"author\").distinct()\\\n",
    "    .rdd.map(lambda r: (r.subreddit, [r.author]))\\\n",
    "    .reduceByKey(lambda a,b: a+b).collect()\n",
    "\n",
    "similarity_users = []\n",
    "for sr1 in users:\n",
    "    for sr2 in users:\n",
    "        similarity_users.append((sr1[0], sr2[0], jaccard_similarity(sr1[1], sr2[1])))\n",
    "        \n",
    "similarity_matrix_users = pd.DataFrame(similarity_users).pivot(index=0, columns=1, values=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(similarity_matrix_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4. Language vs. Users similarity\n",
    "    \n",
    "* Visualize the similarity scores based on word (**B2.3.**) and user (**B3**) similarity on the x and y axes respectively for the subreddit `NBA` compared to all the other subreddits. Do some semantically meaningful groups emerge? Provide clear explanataions of your observations.\n",
    "* Furthermore, do you observe differences in similarities between various sports-related subreddits in the dataset? Please provide explanations of the reasons behind these differences, if any!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sr = \"nba\"      # 选定 NBA 子版块作为参考\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "u = similarity_matrix_users[similarity_matrix_users.index == sr].drop(sr, axis=1).to_numpy()[0]\n",
    "w = similarity_matrix_words[similarity_matrix_words.index == sr].drop(sr, axis=1).to_numpy()[0]\n",
    "ax = plt.scatter(w, u)\n",
    "\n",
    "c=similarity_matrix_users[similarity_matrix_users.index == sr].drop(sr, axis=1).columns.tolist()\n",
    "\n",
    "for i in range(0, len(u)):\n",
    "    plt.annotate(c[i], xy=(w[i], u[i]), rotation=20)    # plt.annotate: 在每个点的坐标位置(w[i], u[i])处标注对应的子版块名称\n",
    "    \n",
    "plt.xlabel(\"Words Jaccard\")\n",
    "plt.ylabel(\"Users Jaccard\")\n",
    "plt.title(\"NBA similarity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
